{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Tokenizers for Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Different Tokenizers on Texts"
      ],
      "metadata": {
        "id": "_o17mOxiBBCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Packages"
      ],
      "metadata": {
        "id": "ncO56_43BG0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "CqjPcQERBAcH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Dataset"
      ],
      "metadata": {
        "id": "hHkidoYaCrq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Data from CSV\n",
        "df = pd.read_csv('tweets_01-08-2021.csv')"
      ],
      "metadata": {
        "id": "kPTNVrMKBGMt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Method for Displaying Tokens"
      ],
      "metadata": {
        "id": "7g46hY6GDtXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_tokens(text, tokens_collect):\n",
        "  for text, tokens in zip(text,tokens_collect):\n",
        "    print(\"Text:   \",text)\n",
        "    print(\"Tokens: \",*tokens,sep=\"|\")"
      ],
      "metadata": {
        "id": "vO5XpVDjDsqA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Number of Tweets to be considered"
      ],
      "metadata": {
        "id": "KH4SPEDDCwC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose the Number of Tweets to be considered for tokenization\n",
        "num = 10"
      ],
      "metadata": {
        "id": "TI3fk53NBUi2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Different Tokenizers on Text for Tweets"
      ],
      "metadata": {
        "id": "LzLd4botBwMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tweets - Tokenizer"
      ],
      "metadata": {
        "id": "Ezihd2ZyB1bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokenizing Using Tweet Tokenizer: \")\n",
        "tokenizer = nltk.tokenize.TweetTokenizer()\n",
        "df['tokens'] = df['text'].apply(tokenizer.tokenize)\n",
        "display_tokens(list(df['text'])[:num],list(df['tokens'])[:num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXHWGh2QBvwX",
        "outputId": "0d8370cc-a78e-43d1-9e06-87556d7aa2e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Using Tweet Tokenizer: \n",
            "Text:    Republicans and Democrats have both created our economic problems.\n",
            "Tokens: |Republicans|and|Democrats|have|both|created|our|economic|problems|.\n",
            "Text:    I was thrilled to be back in the Great city of Charlotte, North Carolina with thousands of hardworking American Patriots who love our Country, cherish our values, respect our laws, and always put AMERICA FIRST! Thank you for a wonderful evening!! #KAG2020 https://t.co/dNJZfRsl9y\n",
            "Tokens: |I|was|thrilled|to|be|back|in|the|Great|city|of|Charlotte|,|North|Carolina|with|thousands|of|hardworking|American|Patriots|who|love|our|Country|,|cherish|our|values|,|respect|our|laws|,|and|always|put|AMERICA|FIRST|!|Thank|you|for|a|wonderful|evening|!|!|#KAG2020|https://t.co/dNJZfRsl9y\n",
            "Text:    RT @CBS_Herridge: READ: Letter to surveillance court obtained by CBS News questions where there will be further disciplinary action and cho…\n",
            "Tokens: |RT|@CBS_Herridge|:|READ|:|Letter|to|surveillance|court|obtained|by|CBS|News|questions|where|there|will|be|further|disciplinary|action|and|cho|…\n",
            "Text:    The Unsolicited Mail In Ballot Scam is a major threat to our Democracy, &amp; the Democrats know it. Almost all recent elections using this system, even though much smaller &amp;  with far fewer Ballots to count, have ended up being a disaster. Large numbers of missing Ballots &amp; Fraud!\n",
            "Tokens: |The|Unsolicited|Mail|In|Ballot|Scam|is|a|major|threat|to|our|Democracy|,|&|the|Democrats|know|it|.|Almost|all|recent|elections|using|this|system|,|even|though|much|smaller|&|with|far|fewer|Ballots|to|count|,|have|ended|up|being|a|disaster|.|Large|numbers|of|missing|Ballots|&|Fraud|!\n",
            "Text:    RT @MZHemingway: Very friendly telling of events here about Comey's apparent leaking to compliant media. If you read those articles and tho…\n",
            "Tokens: |RT|@MZHemingway|:|Very|friendly|telling|of|events|here|about|Comey's|apparent|leaking|to|compliant|media|.|If|you|read|those|articles|and|tho|…\n",
            "Text:    RT @WhiteHouse: President @realDonaldTrump announced historic steps to protect the Constitutional right to pray in public schools! https://…\n",
            "Tokens: |RT|@WhiteHouse|:|President|@realDonaldTrump|announced|historic|steps|to|protect|the|Constitutional|right|to|pray|in|public|schools|!|https://…\n",
            "Text:    Getting a little exercise this morning! https://t.co/fyAAcbhbgk\n",
            "Tokens: |Getting|a|little|exercise|this|morning|!|https://t.co/fyAAcbhbgk\n",
            "Text:    https://t.co/4qwCKQOiOw\n",
            "Tokens: |https://t.co/4qwCKQOiOw\n",
            "Text:    https://t.co/VlEu8yyovv\n",
            "Tokens: |https://t.co/VlEu8yyovv\n",
            "Text:    https://t.co/z5CRqHO8vg\n",
            "Tokens: |https://t.co/z5CRqHO8vg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NLTK's Word Tokenizer"
      ],
      "metadata": {
        "id": "p_-dH33OB4aN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading PUNKT Dependency"
      ],
      "metadata": {
        "id": "kF5AVXK4DU-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KP07uZeDZgj",
        "outputId": "706575bc-7f86-4476-aa6d-f84bfd367c12"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nTokenizing Using NLTK's Recommended Word Tokenizer: \")\n",
        "df['tokens'] = df['text'].apply(nltk.tokenize.word_tokenize)\n",
        "display_tokens(list(df['text'])[:num],list(df['tokens'])[:num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C8xXHdpB9zx",
        "outputId": "0fc02f60-9910-42ed-90d1-02bdba4f5977"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Tokenizing Using NLTK's Recommended Word Tokenizer: \n",
            "Text:    Republicans and Democrats have both created our economic problems.\n",
            "Tokens: |Republicans|and|Democrats|have|both|created|our|economic|problems|.\n",
            "Text:    I was thrilled to be back in the Great city of Charlotte, North Carolina with thousands of hardworking American Patriots who love our Country, cherish our values, respect our laws, and always put AMERICA FIRST! Thank you for a wonderful evening!! #KAG2020 https://t.co/dNJZfRsl9y\n",
            "Tokens: |I|was|thrilled|to|be|back|in|the|Great|city|of|Charlotte|,|North|Carolina|with|thousands|of|hardworking|American|Patriots|who|love|our|Country|,|cherish|our|values|,|respect|our|laws|,|and|always|put|AMERICA|FIRST|!|Thank|you|for|a|wonderful|evening|!|!|#|KAG2020|https|:|//t.co/dNJZfRsl9y\n",
            "Text:    RT @CBS_Herridge: READ: Letter to surveillance court obtained by CBS News questions where there will be further disciplinary action and cho…\n",
            "Tokens: |RT|@|CBS_Herridge|:|READ|:|Letter|to|surveillance|court|obtained|by|CBS|News|questions|where|there|will|be|further|disciplinary|action|and|cho…\n",
            "Text:    The Unsolicited Mail In Ballot Scam is a major threat to our Democracy, &amp; the Democrats know it. Almost all recent elections using this system, even though much smaller &amp;  with far fewer Ballots to count, have ended up being a disaster. Large numbers of missing Ballots &amp; Fraud!\n",
            "Tokens: |The|Unsolicited|Mail|In|Ballot|Scam|is|a|major|threat|to|our|Democracy|,|&|amp|;|the|Democrats|know|it|.|Almost|all|recent|elections|using|this|system|,|even|though|much|smaller|&|amp|;|with|far|fewer|Ballots|to|count|,|have|ended|up|being|a|disaster|.|Large|numbers|of|missing|Ballots|&|amp|;|Fraud|!\n",
            "Text:    RT @MZHemingway: Very friendly telling of events here about Comey's apparent leaking to compliant media. If you read those articles and tho…\n",
            "Tokens: |RT|@|MZHemingway|:|Very|friendly|telling|of|events|here|about|Comey|'s|apparent|leaking|to|compliant|media|.|If|you|read|those|articles|and|tho…\n",
            "Text:    RT @WhiteHouse: President @realDonaldTrump announced historic steps to protect the Constitutional right to pray in public schools! https://…\n",
            "Tokens: |RT|@|WhiteHouse|:|President|@|realDonaldTrump|announced|historic|steps|to|protect|the|Constitutional|right|to|pray|in|public|schools|!|https|:|//…\n",
            "Text:    Getting a little exercise this morning! https://t.co/fyAAcbhbgk\n",
            "Tokens: |Getting|a|little|exercise|this|morning|!|https|:|//t.co/fyAAcbhbgk\n",
            "Text:    https://t.co/4qwCKQOiOw\n",
            "Tokens: |https|:|//t.co/4qwCKQOiOw\n",
            "Text:    https://t.co/VlEu8yyovv\n",
            "Tokens: |https|:|//t.co/VlEu8yyovv\n",
            "Text:    https://t.co/z5CRqHO8vg\n",
            "Tokens: |https|:|//t.co/z5CRqHO8vg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regular-Expression Tokenizer"
      ],
      "metadata": {
        "id": "ktqA3nFACEZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Regular Expression for Tokenization"
      ],
      "metadata": {
        "id": "qBGtOp9HCWkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining tokenizers specific parameters\n",
        "RE_TOKEN = re.compile(r\"\"\"\n",
        "               ( [#]?[@\\w'’\\.\\-\\:]*\\w\n",
        "               | [:;<]\\-?[\\)\\(3]     \n",
        "               | [\\U0001F100-\\U0001FFFF]\n",
        "               )\n",
        "               \"\"\", re.VERBOSE)"
      ],
      "metadata": {
        "id": "pU3vByZyBgQU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nTokenizing Using Regex Tokenizer: \")\n",
        "tokenizer = nltk.tokenize.RegexpTokenizer(RE_TOKEN.pattern, flags=re.VERBOSE)\n",
        "df['tokens'] = df['text'].apply(tokenizer.tokenize)\n",
        "display_tokens(list(df['text'])[:num],list(df['tokens'])[:num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1tJcL9XB-UY",
        "outputId": "172e2d2d-9f74-4775-efb8-fe336dbe6de1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Tokenizing Using Regex Tokenizer: \n",
            "Text:    Republicans and Democrats have both created our economic problems.\n",
            "Tokens: |Republicans|and|Democrats|have|both|created|our|economic|problems\n",
            "Text:    I was thrilled to be back in the Great city of Charlotte, North Carolina with thousands of hardworking American Patriots who love our Country, cherish our values, respect our laws, and always put AMERICA FIRST! Thank you for a wonderful evening!! #KAG2020 https://t.co/dNJZfRsl9y\n",
            "Tokens: |I|was|thrilled|to|be|back|in|the|Great|city|of|Charlotte|North|Carolina|with|thousands|of|hardworking|American|Patriots|who|love|our|Country|cherish|our|values|respect|our|laws|and|always|put|AMERICA|FIRST|Thank|you|for|a|wonderful|evening|#KAG2020|https|t.co|dNJZfRsl9y\n",
            "Text:    RT @CBS_Herridge: READ: Letter to surveillance court obtained by CBS News questions where there will be further disciplinary action and cho…\n",
            "Tokens: |RT|@CBS_Herridge|READ|Letter|to|surveillance|court|obtained|by|CBS|News|questions|where|there|will|be|further|disciplinary|action|and|cho\n",
            "Text:    The Unsolicited Mail In Ballot Scam is a major threat to our Democracy, &amp; the Democrats know it. Almost all recent elections using this system, even though much smaller &amp;  with far fewer Ballots to count, have ended up being a disaster. Large numbers of missing Ballots &amp; Fraud!\n",
            "Tokens: |The|Unsolicited|Mail|In|Ballot|Scam|is|a|major|threat|to|our|Democracy|amp|the|Democrats|know|it|Almost|all|recent|elections|using|this|system|even|though|much|smaller|amp|with|far|fewer|Ballots|to|count|have|ended|up|being|a|disaster|Large|numbers|of|missing|Ballots|amp|Fraud\n",
            "Text:    RT @MZHemingway: Very friendly telling of events here about Comey's apparent leaking to compliant media. If you read those articles and tho…\n",
            "Tokens: |RT|@MZHemingway|Very|friendly|telling|of|events|here|about|Comey's|apparent|leaking|to|compliant|media|If|you|read|those|articles|and|tho\n",
            "Text:    RT @WhiteHouse: President @realDonaldTrump announced historic steps to protect the Constitutional right to pray in public schools! https://…\n",
            "Tokens: |RT|@WhiteHouse|President|@realDonaldTrump|announced|historic|steps|to|protect|the|Constitutional|right|to|pray|in|public|schools|https\n",
            "Text:    Getting a little exercise this morning! https://t.co/fyAAcbhbgk\n",
            "Tokens: |Getting|a|little|exercise|this|morning|https|t.co|fyAAcbhbgk\n",
            "Text:    https://t.co/4qwCKQOiOw\n",
            "Tokens: |https|t.co|4qwCKQOiOw\n",
            "Text:    https://t.co/VlEu8yyovv\n",
            "Tokens: |https|t.co|VlEu8yyovv\n",
            "Text:    https://t.co/z5CRqHO8vg\n",
            "Tokens: |https|t.co|z5CRqHO8vg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Toktok - Tokenizer"
      ],
      "metadata": {
        "id": "gVw9d_5fCOsE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2qj_1bfAthj",
        "outputId": "8f438f23-9185-40c9-cf22-fd9eb9a6070f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Tokenizing Using Toktok Tokenizer: \n",
            "Text:    Republicans and Democrats have both created our economic problems.\n",
            "Tokens: |Republicans|and|Democrats|have|both|created|our|economic|problems|.\n",
            "Text:    I was thrilled to be back in the Great city of Charlotte, North Carolina with thousands of hardworking American Patriots who love our Country, cherish our values, respect our laws, and always put AMERICA FIRST! Thank you for a wonderful evening!! #KAG2020 https://t.co/dNJZfRsl9y\n",
            "Tokens: |I|was|thrilled|to|be|back|in|the|Great|city|of|Charlotte|,|North|Carolina|with|thousands|of|hardworking|American|Patriots|who|love|our|Country|,|cherish|our|values|,|respect|our|laws|,|and|always|put|AMERICA|FIRST|!|Thank|you|for|a|wonderful|evening|!|!|#KAG2020|https://t.co/dNJZfRsl9y\n",
            "Text:    RT @CBS_Herridge: READ: Letter to surveillance court obtained by CBS News questions where there will be further disciplinary action and cho…\n",
            "Tokens: |RT|@CBS_Herridge|:|READ|:|Letter|to|surveillance|court|obtained|by|CBS|News|questions|where|there|will|be|further|disciplinary|action|and|cho|…\n",
            "Text:    The Unsolicited Mail In Ballot Scam is a major threat to our Democracy, &amp; the Democrats know it. Almost all recent elections using this system, even though much smaller &amp;  with far fewer Ballots to count, have ended up being a disaster. Large numbers of missing Ballots &amp; Fraud!\n",
            "Tokens: |The|Unsolicited|Mail|In|Ballot|Scam|is|a|major|threat|to|our|Democracy|,|&amp|;|the|Democrats|know|it.|Almost|all|recent|elections|using|this|system|,|even|though|much|smaller|&amp|;|with|far|fewer|Ballots|to|count|,|have|ended|up|being|a|disaster.|Large|numbers|of|missing|Ballots|&amp|;|Fraud|!\n",
            "Text:    RT @MZHemingway: Very friendly telling of events here about Comey's apparent leaking to compliant media. If you read those articles and tho…\n",
            "Tokens: |RT|@MZHemingway|:|Very|friendly|telling|of|events|here|about|Comey|'|s|apparent|leaking|to|compliant|media.|If|you|read|those|articles|and|tho|…\n",
            "Text:    RT @WhiteHouse: President @realDonaldTrump announced historic steps to protect the Constitutional right to pray in public schools! https://…\n",
            "Tokens: |RT|@WhiteHouse|:|President|@realDonaldTrump|announced|historic|steps|to|protect|the|Constitutional|right|to|pray|in|public|schools|!|https://|…\n",
            "Text:    Getting a little exercise this morning! https://t.co/fyAAcbhbgk\n",
            "Tokens: |Getting|a|little|exercise|this|morning|!|https://t.co/fyAAcbhbgk\n",
            "Text:    https://t.co/4qwCKQOiOw\n",
            "Tokens: |https://t.co/4qwCKQOiOw\n",
            "Text:    https://t.co/VlEu8yyovv\n",
            "Tokens: |https://t.co/VlEu8yyovv\n",
            "Text:    https://t.co/z5CRqHO8vg\n",
            "Tokens: |https://t.co/z5CRqHO8vg\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\\nTokenizing Using Toktok Tokenizer: \")\n",
        "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
        "df['tokens'] = df['text'].apply(tokenizer.tokenize)\n",
        "display_tokens(list(df['text'])[:num],list(df['tokens'])[:num])"
      ]
    }
  ]
}